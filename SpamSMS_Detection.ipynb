{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a seq_to_1 problem (needs encoder):<br>\n",
    "Process:<br>\n",
    "1:Load, clean the data and tokenize<br>\n",
    "2:Encode the words (Create dictionary of words)<br>\n",
    "3:Word embedding<br>\n",
    "4:Build rnn model (Create embdding and LSTM layers)<br>\n",
    "5:Run and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and clean the messages as well as encoding the lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_clean(filepath):\n",
    "    '''Load & clean the data'''\n",
    "\n",
    "    #Load Data\n",
    "    data = pd.read_csv(filepath)\n",
    "    #rows_number=data.shape[0]\n",
    "    messages=[]\n",
    "    for message in data['v2']:\n",
    "        #Extra celaning of text before Keras tokenization \n",
    "        #Removing stopwords\n",
    "        nltk.download(\"stopwords\")\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        message=' '.join(i for i in message.split() if i not in stop_words)\n",
    "        #Here, BeauifulSoup is used to encode not completely deccoded text(decoded from html code) to html code again\n",
    "        message = BeautifulSoup(message, 'lxml')\n",
    "        #Later we strip away tags in the html encodings and decode them to text\n",
    "        message=message.get_text()\n",
    "        messages.append(message)\n",
    "    \n",
    "    #Encode labels\n",
    "    labels=[]\n",
    "    [labels.append(0) if label==\"spam\" else labels.append(1) for label in data['v1']]\n",
    "    labels = np.asarray(labels)\n",
    "    return messages,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tokenize sentences and encode their words to integers, Keras is helpful here for normalization ,tokenization as well as generating word indexes and padding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode_words(sentences):\n",
    "    '''Convert words to numbers (Create dictionary of words)'''\n",
    "    \n",
    "    #Since we read from csv, we need to do some encoding\n",
    "    #Remove u'\n",
    "    sentences=[x.encode('utf-8') for x in sentences]\n",
    "    #Remove \\xHH characters\n",
    "    sentences=[re.sub(r'[^\\x00-\\x7f]',r'', x) for x in sentences]\n",
    "    \n",
    "    #Keras tokenization (punctualtion removal, normalization and split by white space)\n",
    "    tokenize = Tokenizer()\n",
    "    #Fit tokenizer to the whole data\n",
    "    tokenize.fit_on_texts(sentences)\n",
    "    data_seq=tokenize.texts_to_sequences(sentences)\n",
    "    word_index = tokenize.word_index\n",
    "    #Choose the maximum number of tokens in all sequences \n",
    "    num_tokens = [len(tokens) for tokens in data_seq]\n",
    "    max_seq_length=np.max(num_tokens)\n",
    "    #Make sequences to have the same length(add extra zeros to the beginnings)\n",
    "    data_seq = pad_sequences(data_seq, maxlen = max_seq_length,\n",
    "                                padding='pre', truncating='pre')\n",
    "    #print(data_seq)\n",
    "    return data_seq,word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    '''Define model inputs'''\n",
    "    \n",
    "    #Resert the default graph \n",
    "    tf.reset_default_graph()\n",
    "    #Model's placeholders for inputs\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    return inputs,targets,keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the RNN model with 2 layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_RNN(vocabulary_size,embedding_size,inputs,num_hidden,lstm_layer_numbers,keep_prob,batch_size):\n",
    "    '''Build RNN'''\n",
    "\n",
    "    #Embedding Layer\n",
    "    '''Intialize embeddings for the words. Embedding layer connects the words to the LSTM layers (words are embedded to the embedding_size vectors instead of vocabulary size vectors or one hot vectors). Here, provided by tensorflow, we used random_uniform distribution to create embeddings'''\n",
    "    embedding = tf.Variable(tf.random_uniform((vocabulary_size, embedding_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs)\n",
    "    #Define LSTM layers\n",
    "    lstms=[]\n",
    "    for i in range(lstm_layer_numbers):\n",
    "        lstms.append(tf.contrib.rnn.BasicLSTMCell(num_hidden))\n",
    "    # Add regularization dropout to the LSTM cells\n",
    "    drops = [tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob) for lstm in lstms]\n",
    "    # Stack up multiple LSTM layers\n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell(drops)\n",
    "    # Getting the initial state\n",
    "    initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(stacked_lstm, embed, initial_state=initial_state)\n",
    "        \n",
    "    return initial_state, outputs, final_state\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "def get_batches(x, y, batch_size):\n",
    "    '''Using generator to return batches for train, validation and test data'''\n",
    "\n",
    "    n_batches = len(x)//batch_size\n",
     "    '''In case that the batch_size is not a multiple of data size in order to create batches with the same sizes, this line will ignore the last words in text that cannot create a full batch (although, one can consider those last words and add enough word from the beginning of the text to create a full size batch)'''\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data\n",
    "emaildata_file=\"./spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and clean data; return clean messages and labels\n",
    "text_messages,labels=load_clean(emaildata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words to int\n",
    "data_sequences,word_index=encode_words(text_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raining': 1592,\n",
       " 'yellow': 4011,\n",
       " 'four': 2311,\n",
       " 'prices': 6549,\n",
       " 'woods': 6739,\n",
       " \"friend's\": 2388,\n",
       " 'hanging': 1973,\n",
       " 'looking': 396,\n",
       " 'electricity': 3752,\n",
       " 'scold': 3754,\n",
       " 'lord': 6828,\n",
       " 'rp176781': 4605,\n",
       " 'callin': 2480,\n",
       " 'ew': 6749,\n",
       " 'hearin': 8343,\n",
       " 'screaming': 1608,\n",
       " 'disturb': 1093,\n",
       " 'prize': 107,\n",
       " 'andre': 8476,\n",
       " 'smsing': 7980,\n",
       " 'wednesday': 1274,\n",
       " 'oooh': 3205,\n",
       " 'specially': 1072,\n",
       " 'nigh': 7532,\n",
       " 'tired': 809,\n",
       " 'snuggles': 8160,\n",
       " \"'wnevr\": 6818,\n",
       " 'second': 621,\n",
       " 'attended': 7746,\n",
       " 'txtno': 3131,\n",
       " 'available': 616,\n",
       " 'scraped': 8165,\n",
       " '2kbsubject': 4899,\n",
       " 'scallies': 7419,\n",
       " 'errors': 5266,\n",
       " 'cooking': 2231,\n",
       " 'fingers': 1223,\n",
       " 'maraikara': 6845,\n",
       " 'hero': 5162,\n",
       " \"how've\": 6751,\n",
       " 'y87': 6931,\n",
       " 'here': 233,\n",
       " 'specialise': 5727,\n",
       " '47': 7730,\n",
       " 'china': 2793,\n",
       " 'dogwood': 7964,\n",
       " 'dorm': 3261,\n",
       " '08718711108': 4829,\n",
       " 'previews': 5968,\n",
       " '84122': 5275,\n",
       " 'w111wx': 2211,\n",
       " 'kids': 1035,\n",
       " '84128': 2631,\n",
       " 'eastenders': 3427,\n",
       " '09058091870': 7880,\n",
       " \"i'd\": 854,\n",
       " \"i'm\": 6,\n",
       " 'spotty': 6044,\n",
       " 'golden': 6590,\n",
       " \"ta's\": 4419,\n",
       " \"dat's\": 3171,\n",
       " 'replace': 4343,\n",
       " 'brought': 2172,\n",
       " 'sterm': 8621,\n",
       " '000pes': 5744,\n",
       " 'txt': 28,\n",
       " 'univ': 7383,\n",
       " '9t': 3161,\n",
       " 'cheating': 4109,\n",
       " 'spoke': 1477,\n",
       " 'ec2a': 1668,\n",
       " 'browse': 5573,\n",
       " 'dnt': 818,\n",
       " 'music': 485,\n",
       " 'passport': 7259,\n",
       " 'strike': 2873,\n",
       " 'until': 7549,\n",
       " 'paperwork': 3094,\n",
       " 'holy': 3815,\n",
       " 'relax': 1506,\n",
       " 'successful': 2544,\n",
       " 'brings': 1106,\n",
       " 'premarica': 6284,\n",
       " 'hols': 1913,\n",
       " 'yahoo': 1209,\n",
       " 'hurt': 528,\n",
       " '99': 3455,\n",
       " 'glass': 5361,\n",
       " '47per': 5980,\n",
       " 'hole': 5020,\n",
       " 'hold': 776,\n",
       " '95': 5385,\n",
       " 'up4': 3704,\n",
       " 'tirupur': 2475,\n",
       " 'itself': 1480,\n",
       " 'wana': 943,\n",
       " 'drvgsto': 4901,\n",
       " 'pints': 7613,\n",
       " 'smth': 681,\n",
       " 'want': 26,\n",
       " 'organizer': 5614,\n",
       " 'preferably': 2167,\n",
       " 'hon': 3957,\n",
       " 'hoo': 7609,\n",
       " 'travel': 1772,\n",
       " 'how': 31,\n",
       " 'hot': 526,\n",
       " 'hor': 2937,\n",
       " 'hos': 8379,\n",
       " 'hop': 1311,\n",
       " 'significance': 4694,\n",
       " '1172': 8208,\n",
       " 'beauty': 4255,\n",
       " 'yun': 1794,\n",
       " 'wan2': 4127,\n",
       " 'plyr': 4966,\n",
       " 'wrong': 748,\n",
       " 'lololo': 6073,\n",
       " 'bsnl': 6320,\n",
       " 'types': 5465,\n",
       " 'ibored': 8519,\n",
       " 'aroundn': 6954,\n",
       " 'wins': 1685,\n",
       " 'yunny': 3934,\n",
       " 'alian': 6227,\n",
       " 'age16': 1119,\n",
       " 'tulip': 3430,\n",
       " 'areyouunique': 4496,\n",
       " 'keeps': 3683,\n",
       " 'lambda': 5889,\n",
       " 'wind': 3459,\n",
       " 'wine': 932,\n",
       " 'wc1n': 8783,\n",
       " 'afterwards': 8455,\n",
       " \"dramastorm's\": 6465,\n",
       " 'vary': 1513,\n",
       " 'kickoff': 3422,\n",
       " '82050': 3720,\n",
       " '87575': 1894,\n",
       " 'welcomes': 4028,\n",
       " 'lovingly': 3637,\n",
       " 'fit': 2374,\n",
       " 'bringing': 2011,\n",
       " 'fix': 1686,\n",
       " 'max10mins': 1621,\n",
       " '4eva': 4334,\n",
       " 'matured': 2014,\n",
       " '09095350301': 8642,\n",
       " 'wales': 2276,\n",
       " 'hidden': 7726,\n",
       " 'nokia6600': 3712,\n",
       " 'easier': 2126,\n",
       " 'duvet': 8052,\n",
       " 'vouchers': 550,\n",
       " 'effects': 3234,\n",
       " 'schools': 3287,\n",
       " 'go2sri': 7321,\n",
       " 'silver': 3567,\n",
       " 'rumour': 3624,\n",
       " 'fetching': 4812,\n",
       " 'dload': 1790,\n",
       " 'nattil': 7273,\n",
       " 'arrow': 6192,\n",
       " 'addicted': 2090,\n",
       " 'burial': 4981,\n",
       " 'financial': 6226,\n",
       " 'fgkslpopw': 8247,\n",
       " 'series': 1905,\n",
       " 'allah': 1700,\n",
       " 'spider': 4359,\n",
       " 'bowls': 6694,\n",
       " 'strips': 5240,\n",
       " \"we'd\": 1938,\n",
       " '2day': 1099,\n",
       " 'ring': 576,\n",
       " 'rt': 5660,\n",
       " 'ru': 1868,\n",
       " 'rv': 4982,\n",
       " 'forwarding': 5961,\n",
       " 'rr': 6330,\n",
       " 'rs': 726,\n",
       " 'ha': 680,\n",
       " 'help08714742804': 5520,\n",
       " 'sms': 193,\n",
       " 'rd': 1838,\n",
       " 're': 1404,\n",
       " 'noice': 7627,\n",
       " '09061701851': 7438,\n",
       " 'ofcourse': 8750,\n",
       " 'dracula': 3654,\n",
       " 'toking': 7994,\n",
       " 'sheet': 6317,\n",
       " 'ate': 1573,\n",
       " 'shelves': 6135,\n",
       " 'atm': 1679,\n",
       " 'ups': 4525,\n",
       " 'shipped': 3115,\n",
       " \"today's\": 1354,\n",
       " 'clothes': 4247,\n",
       " 'veggie': 5286,\n",
       " 'kfc': 7742,\n",
       " 'hear': 349,\n",
       " 'ente': 5168,\n",
       " \"b'tooth\": 5844,\n",
       " 'basketball': 7288,\n",
       " 'service': 177,\n",
       " '09061743386': 4219,\n",
       " 'engagement': 8080,\n",
       " 'xin': 7300,\n",
       " 'needed': 1921,\n",
       " 'listed': 7291,\n",
       " 'loosu': 7777,\n",
       " 'hiya': 1135,\n",
       " 'listen': 787,\n",
       " 'clubmoby': 8125,\n",
       " 'wisdom': 2906,\n",
       " 'termsapply': 8175,\n",
       " 'trek': 4870,\n",
       " 'peril': 7090,\n",
       " 'showed': 7262,\n",
       " 'saeed': 5998,\n",
       " 'tree': 2421,\n",
       " 'likely': 2478,\n",
       " 'project': 779,\n",
       " 'percentages': 7083,\n",
       " 'bridgwater': 4796,\n",
       " 'feeling': 531,\n",
       " 'boston': 1658,\n",
       " '09061749602': 5093,\n",
       " 'selflessness': 6780,\n",
       " '9755': 4709,\n",
       " '9758': 8158,\n",
       " 'affairs': 2922,\n",
       " 'escalator': 5149,\n",
       " 'flippin': 5294,\n",
       " 'responsible': 5679,\n",
       " 'witot': 5451,\n",
       " 'andros': 4056,\n",
       " 'okie': 605,\n",
       " 'causing': 4158,\n",
       " 'doors': 2697,\n",
       " 'hum': 6209,\n",
       " 'shall': 357,\n",
       " 'doin': 1057,\n",
       " 'victoria': 8684,\n",
       " 'doit': 5023,\n",
       " 'swiss': 3914,\n",
       " 'laxinorficated': 7144,\n",
       " 'mouth': 3019,\n",
       " 'daywith': 6776,\n",
       " 'letter': 1900,\n",
       " 'thriller': 6909,\n",
       " 'cops': 8710,\n",
       " 'marsms': 6060,\n",
       " 'camp': 7690,\n",
       " 'passes': 7392,\n",
       " 'everythin': 5356,\n",
       " '41685': 3342,\n",
       " 'tech': 3392,\n",
       " '84484': 7572,\n",
       " 'scream': 1531,\n",
       " 'came': 427,\n",
       " 'marvel': 8753,\n",
       " 'saying': 584,\n",
       " 'bomb': 8270,\n",
       " 'prin': 7671,\n",
       " 'insects': 5372,\n",
       " 'advisors': 8363,\n",
       " 'teresa': 5814,\n",
       " 'prix': 4782,\n",
       " 'gauge': 5430,\n",
       " 'buzzzz': 6696,\n",
       " 'participate': 6803,\n",
       " 'lessons': 1087,\n",
       " 'busy': 544,\n",
       " \"u'll\": 1399,\n",
       " 'menu': 1309,\n",
       " 'appreciated': 3485,\n",
       " 'cougar': 5177,\n",
       " 'touched': 2348,\n",
       " 'rich': 2784,\n",
       " 'rice': 3385,\n",
       " 'pocked': 7810,\n",
       " 'plate': 6968,\n",
       " '0871277810810': 3020,\n",
       " 'platt': 6042,\n",
       " 'uworld': 8579,\n",
       " 'tips': 7657,\n",
       " 'lmao': 1422,\n",
       " 'bus8': 5136,\n",
       " 'kittum': 7274,\n",
       " 'asssssholeeee': 7566,\n",
       " 'piggy': 4843,\n",
       " 'respond': 1719,\n",
       " 'disaster': 8376,\n",
       " 'fair': 2286,\n",
       " 'rupaul': 5949,\n",
       " 'goodnight': 1089,\n",
       " 'result': 2004,\n",
       " 'bleh': 3374,\n",
       " 'best': 241,\n",
       " 'lotz': 8212,\n",
       " 'ctargg': 5041,\n",
       " 'lots': 653,\n",
       " 'lotr': 2686,\n",
       " 'wikipedia': 4826,\n",
       " '80122300p': 6401,\n",
       " 'stamps': 2592,\n",
       " 'score': 2624,\n",
       " 'glasgow': 5570,\n",
       " 'men': 1070,\n",
       " 'nationwide': 7573,\n",
       " 'nature': 1605,\n",
       " 'rolled': 6416,\n",
       " 'rajini': 5517,\n",
       " 'icicibank': 3559,\n",
       " 'wtc': 6599,\n",
       " 'wtf': 1987,\n",
       " 'wth': 7375,\n",
       " 'roller': 8098,\n",
       " 'pity': 8816,\n",
       " 'accident': 2905,\n",
       " 'brown': 6002,\n",
       " 'country': 1302,\n",
       " 'macedonia': 4371,\n",
       " 'planned': 1449,\n",
       " 'lookin': 1611,\n",
       " 'tomarrow': 2346,\n",
       " 'machan': 1908,\n",
       " 'login': 1372,\n",
       " 'argue': 1957,\n",
       " 'asked': 415,\n",
       " '30th': 4495,\n",
       " 'itried2tell': 5791,\n",
       " '2nd': 382,\n",
       " 'happenin': 5396,\n",
       " 'darlin': 725,\n",
       " 'sk38xh': 1396,\n",
       " '250': 634,\n",
       " '255': 8153,\n",
       " '9ja': 2453,\n",
       " 'billing': 7901,\n",
       " 'shouting': 5583,\n",
       " 'fri': 742,\n",
       " 'fro': 5085,\n",
       " 'frm': 784,\n",
       " 'much': 74,\n",
       " 'wuld': 4031,\n",
       " 'stadium': 6568,\n",
       " 'parents': 720,\n",
       " 'obese': 5207,\n",
       " 'life': 119,\n",
       " 'dave': 2450,\n",
       " 'lift': 1345,\n",
       " 'chile': 7463,\n",
       " 'child': 2280,\n",
       " '25p': 1235,\n",
       " 'spin': 7802,\n",
       " 'bridal': 7134,\n",
       " 'chill': 2647,\n",
       " 'unsold': 1774,\n",
       " '3680': 3072,\n",
       " '09058091854': 3435,\n",
       " '2wks': 3058,\n",
       " 'selfindependence': 7544,\n",
       " 'meetin': 2059,\n",
       " 'k': 52,\n",
       " '42810': 8263,\n",
       " 'a21': 5702,\n",
       " 'congratulation': 8350,\n",
       " 'played': 2086,\n",
       " '078': 8513,\n",
       " 'player': 719,\n",
       " 'feed': 8682,\n",
       " 'things': 204,\n",
       " 'honi': 7599,\n",
       " 'tgxxrz': 4704,\n",
       " 'dha': 5971,\n",
       " 'hont': 7711,\n",
       " 'split': 8091,\n",
       " 'babies': 3564,\n",
       " '4fil': 3471,\n",
       " '08718727870150ppm': 8089,\n",
       " 'tops': 8008,\n",
       " 'ppm150': 5090,\n",
       " 'tune': 4942,\n",
       " 'academic': 4278,\n",
       " 'nachos': 7576,\n",
       " 'xxxxxxxxxxxxxx': 7177,\n",
       " 'opinions': 3869,\n",
       " 'gigolo': 7674,\n",
       " '08701752560': 7225,\n",
       " 'dosomething': 6448,\n",
       " 'sleepy': 3991,\n",
       " 'nydc': 3511,\n",
       " '87121': 1888,\n",
       " 'credited': 2121,\n",
       " 'waht': 3601,\n",
       " 'rushing': 8387,\n",
       " 'previous': 2929,\n",
       " 'hai': 1391,\n",
       " 'enters': 4675,\n",
       " 'ham': 2312,\n",
       " 'duffer': 5893,\n",
       " '1lemon': 7852,\n",
       " 'had': 405,\n",
       " 'haf': 497,\n",
       " 'obedient': 6497,\n",
       " 'innocent': 3952,\n",
       " 'east': 4094,\n",
       " 'hat': 8795,\n",
       " 'hav': 447,\n",
       " \"t's\": 1229,\n",
       " 'fromm': 2252,\n",
       " 'possible': 1127,\n",
       " 'twinks': 7418,\n",
       " 'possibly': 6734,\n",
       " 'birth': 2770,\n",
       " 'vday': 3744,\n",
       " 'shadow': 5996,\n",
       " 'unique': 1945,\n",
       " 'stylist': 5625,\n",
       " 'remind': 1863,\n",
       " 'steps': 7512,\n",
       " '9280114': 8148,\n",
       " 'ola': 3512,\n",
       " 'right': 110,\n",
       " 'old': 568,\n",
       " 'crowd': 7909,\n",
       " 'people': 225,\n",
       " 'weds': 6114,\n",
       " 'oli': 5353,\n",
       " 'easy': 373,\n",
       " 'feel': 162,\n",
       " 'fuuuuck': 8557,\n",
       " 'creep': 4002,\n",
       " 'enemies': 7488,\n",
       " '08718725756': 6901,\n",
       " 'for': 172,\n",
       " 'bottom': 2883,\n",
       " 'fox': 6788,\n",
       " 'creative': 7433,\n",
       " 'treadmill': 8590,\n",
       " 'muhommad': 7660,\n",
       " 'wocay': 8686,\n",
       " 'suitemates': 7578,\n",
       " 'dental': 8808,\n",
       " \"hubby's\": 8032,\n",
       " 'colleg': 7373,\n",
       " 'starring': 6452,\n",
       " 'losing': 2021,\n",
       " 'memorable': 4431,\n",
       " 'quiteamuzing': 8073,\n",
       " 'dollars': 1720,\n",
       " 'careabout': 5793,\n",
       " 'o': 838,\n",
       " 'suggestions': 8817,\n",
       " 'slightly': 3118,\n",
       " 'raised': 6170,\n",
       " 'statements': 6370,\n",
       " 'honeymoon': 5645,\n",
       " 'sol': 1434,\n",
       " 'soo': 3325,\n",
       " 'sos': 7536,\n",
       " '69696': 3971,\n",
       " '69698': 3065,\n",
       " 'soz': 8143,\n",
       " 'janx': 5401,\n",
       " '4742': 1942,\n",
       " 'support': 845,\n",
       " 'constantly': 2755,\n",
       " 'halla': 5528,\n",
       " 'greatness': 5346,\n",
       " 'jane': 2640,\n",
       " 'happy': 84,\n",
       " 'b4280703': 3169,\n",
       " 'offer': 330,\n",
       " '6wu': 3438,\n",
       " 'paypal': 5099,\n",
       " 'notifications': 4968,\n",
       " 'talents': 5671,\n",
       " 'fiting': 7662,\n",
       " 'congratulations': 731,\n",
       " 'inside': 1426,\n",
       " 'pest': 5621,\n",
       " 'lays': 3247,\n",
       " 'smashed': 3805,\n",
       " '151': 8651,\n",
       " '150': 637,\n",
       " '153': 3150,\n",
       " 'half8th': 4893,\n",
       " 'textbook': 5783,\n",
       " \"''\": 545,\n",
       " 'exist': 4467,\n",
       " 'accounting': 7498,\n",
       " 'ericsson': 3037,\n",
       " 'dealer': 7737,\n",
       " 'norm150p': 1558,\n",
       " '80160': 5262,\n",
       " 'floor': 2327,\n",
       " 'actor': 3077,\n",
       " 'uttered': 7625,\n",
       " 'flood': 7423,\n",
       " 'role': 1627,\n",
       " 'ambitious': 6613,\n",
       " 'smell': 5050,\n",
       " 'truffles': 3145,\n",
       " \"'t\": 2091,\n",
       " 'intend': 5788,\n",
       " 'fathima': 2739,\n",
       " '07742676969': 3002,\n",
       " 'outage': 7535,\n",
       " 'mre': 8322,\n",
       " 'hollalater': 5070,\n",
       " 'jewelry': 7784,\n",
       " 'nxt': 1400,\n",
       " 'loveme': 3308,\n",
       " 'preponed': 8426,\n",
       " 'cuddled': 6544,\n",
       " '07732584351': 4390,\n",
       " 'broadband': 7211,\n",
       " 'time': 22,\n",
       " 'push': 3909,\n",
       " 'timi': 7403,\n",
       " '6230': 6371,\n",
       " 'sday': 8525,\n",
       " 'chain': 2650,\n",
       " 'saibaba': 8770,\n",
       " 'cudnt': 5166,\n",
       " '3ss': 3241,\n",
       " 'boltblue': 4698,\n",
       " 'oso': 500,\n",
       " 'baller': 8392,\n",
       " \"when's\": 2859,\n",
       " 'overdid': 8567,\n",
       " 'lara': 6034,\n",
       " 'macha': 4885,\n",
       " 'comuk': 1130,\n",
       " 'followin': 4622,\n",
       " 'macho': 2913,\n",
       " 'machi': 4677,\n",
       " 'jeri': 4897,\n",
       " 'k718': 6138,\n",
       " 'prepaid': 3035,\n",
       " 'doke': 6266,\n",
       " 'minuts': 1860,\n",
       " 'cheap': 1034,\n",
       " 'maretare': 7017,\n",
       " \"tyler's\": 8296,\n",
       " 'choice': 1811,\n",
       " 'onwords': 8438,\n",
       " 'pleassssssseeeeee': 4521,\n",
       " '5min': 2355,\n",
       " 'exact': 2131,\n",
       " '28days': 3449,\n",
       " 'minute': 600,\n",
       " 'tear': 1440,\n",
       " 'leave': 191,\n",
       " 'solved': 4032,\n",
       " 'settle': 2835,\n",
       " 'team': 1283,\n",
       " 'loads': 925,\n",
       " 'prevent': 4866,\n",
       " 'spiritual': 8798,\n",
       " 'rents': 3693,\n",
       " 'videochat': 1788,\n",
       " 'sigh': 4060,\n",
       " 'prediction': 4508,\n",
       " 'sign': 1191,\n",
       " '08712402972': 7077,\n",
       " 'erotic': 8643,\n",
       " 'shirts': 2864,\n",
       " 'rentl': 1792,\n",
       " 'workand': 6223,\n",
       " 'headset': 7930,\n",
       " \"'hw\": 3879,\n",
       " 'celebrated': 7119,\n",
       " 'melt': 4217,\n",
       " 'current': 1708,\n",
       " '300': 1882,\n",
       " 'axel': 8194,\n",
       " 'falling': 3630,\n",
       " 'ground': 2610,\n",
       " 'boost': 1852,\n",
       " 'unintentionally': 8538,\n",
       " 'funeral': 4197,\n",
       " 'understanding': 2122,\n",
       " 'yards': 8329,\n",
       " 'address': 519,\n",
       " 'alone': 675,\n",
       " 'along': 2159,\n",
       " 'neville': 6857,\n",
       " 'brilliant': 1867,\n",
       " '300603': 3138,\n",
       " 'wherever': 1574,\n",
       " \"anybody's\": 5975,\n",
       " 'bw': 8155,\n",
       " 'fassyole': 8498,\n",
       " 'studies': 8588,\n",
       " 'influx': 8801,\n",
       " 'love': 24,\n",
       " 'prefer': 2795,\n",
       " 'bloody': 1937,\n",
       " 'fake': 3722,\n",
       " '4jx': 4957,\n",
       " 'gotbabes': 6800,\n",
       " 'sky': 1442,\n",
       " 'crammed': 5978,\n",
       " 'working': 399,\n",
       " 'positive': 8735,\n",
       " 'angry': 630,\n",
       " 'tightly': 6817,\n",
       " 'wicket': 8620,\n",
       " 'opposed': 7067,\n",
       " 'wondering': 1140,\n",
       " 'films': 2894,\n",
       " \"cann't\": 2907,\n",
       " 'trishul': 7607,\n",
       " 'loving': 674,\n",
       " '09065394973': 5930,\n",
       " 'afford': 6364,\n",
       " 'ooooooh': 8668,\n",
       " 'appendix': 6793,\n",
       " 'everywhere': 3017,\n",
       " 'ip4': 1164,\n",
       " 'scratches': 5179,\n",
       " 'easiest': 6334,\n",
       " 'behalf': 7970,\n",
       " 'logos': 3516,\n",
       " 'valued': 796,\n",
       " 'hussey': 5034,\n",
       " 'pretend': 7115,\n",
       " 'lttrs': 3873,\n",
       " 'printing': 6526,\n",
       " 'values': 7121,\n",
       " 'following': 1293,\n",
       " 'logon': 8067,\n",
       " 'mesages': 4268,\n",
       " 'muah': 4333,\n",
       " 'awesome': 599,\n",
       " 'weasels': 6685,\n",
       " 'parachute': 5887,\n",
       " '88066': 2812,\n",
       " 'hides': 8191,\n",
       " 'admirer': 1003,\n",
       " 'offense': 8183,\n",
       " 'dooms': 7189,\n",
       " 'poking': 6923,\n",
       " 'meive': 4775,\n",
       " '62220cncl': 7475,\n",
       " 'fps': 6280,\n",
       " 'elephant': 6911,\n",
       " '69200': 6756,\n",
       " 'lido': 2307,\n",
       " 'laundry': 3735,\n",
       " 'landmark': 7893,\n",
       " '23f': 6007,\n",
       " '23g': 6008,\n",
       " 'spot': 7453,\n",
       " 'dats': 4505,\n",
       " 'suntec': 2651,\n",
       " 'unclaimed': 4919,\n",
       " 'date': 538,\n",
       " 'such': 6659,\n",
       " 'data': 5190,\n",
       " 'brainless': 7051,\n",
       " 'disagreeable': 8454,\n",
       " 'stress': 2509,\n",
       " 'surfing': 1698,\n",
       " 'natural': 2772,\n",
       " 'sp': 1183,\n",
       " 'st': 887,\n",
       " 'complaining': 5745,\n",
       " 'si': 2001,\n",
       " 'sh': 2713,\n",
       " 'so': 33,\n",
       " 'sn': 2553,\n",
       " 'swollen': 7836,\n",
       " 'sc': 5726,\n",
       " 'misplaced': 6377,\n",
       " 'sg': 6832,\n",
       " 'hol': 3313,\n",
       " 'se': 2750,\n",
       " 'sd': 5143,\n",
       " 'drunken': 4114,\n",
       " 'bootydelious': 3021,\n",
       " 'differences': 8294,\n",
       " 'speedchat': 3464,\n",
       " 'years': 464,\n",
       " 'professors': 3257,\n",
       " 'course': 771,\n",
       " 'studentfinancial': 7091,\n",
       " 'konw': 3600,\n",
       " 'disconnect': 4172,\n",
       " 'jia': 3618,\n",
       " 'avin': 8065,\n",
       " 'attraction': 5221,\n",
       " 'jiu': 1711,\n",
       " '930': 3276,\n",
       " 'decades': 8129,\n",
       " 'instantly': 2823,\n",
       " 'conveying': 7720,\n",
       " 'matches': 1236,\n",
       " 'smarter': 4399,\n",
       " 'n9dx': 3106,\n",
       " 'feelin': 3663,\n",
       " 'records': 1770,\n",
       " 'subscribers': 7926,\n",
       " 'sorted': 2637,\n",
       " 'twilight': 3659,\n",
       " 'maintaining': 8660,\n",
       " 'matched': 5519,\n",
       " 'pokkiri': 5220,\n",
       " 'shouted': 2513,\n",
       " '83435': 6424,\n",
       " 'blacko': 8499,\n",
       " 'othrwise': 7885,\n",
       " 'quarter': 8228,\n",
       " 'ovr': 5531,\n",
       " 'retrieve': 3846,\n",
       " 'padhe': 6305,\n",
       " 'receipt': 1802,\n",
       " 'disasters': 6955,\n",
       " 'pataistha': 7353,\n",
       " 'joker': 8286,\n",
       " '83332': 7069,\n",
       " 'blu': 4205,\n",
       " 'alwa': 6827,\n",
       " '83383': 3935,\n",
       " 'wiskey': 3890,\n",
       " 'trauma': 4991,\n",
       " 'internet': 1308,\n",
       " 'hcl': 6357,\n",
       " 'flurries': 7522,\n",
       " 'ppt150x3': 5078,\n",
       " 'sheffield': 3407,\n",
       " '1131': 6985,\n",
       " 'million': 7804,\n",
       " 'possibility': 7552,\n",
       " 'quite': 323,\n",
       " 'grandma': 8009,\n",
       " 'vijaykanth': 8122,\n",
       " 'raed': 3610,\n",
       " 'training': 1249,\n",
       " 'thankyou': 6115,\n",
       " 'rael': 3602,\n",
       " 'dunno': 377,\n",
       " 'swtheart': 2384,\n",
       " 'initiate': 6781,\n",
       " 'massive': 4271,\n",
       " 'dinero': 5743,\n",
       " 'neglect': 4903,\n",
       " '20m12aq': 6540,\n",
       " 'emotion': 7883,\n",
       " 'oni': 1885,\n",
       " 'frwd': 6233,\n",
       " 'spoken': 2056,\n",
       " 'potter': 3523,\n",
       " 'one': 29,\n",
       " 'spanish': 2328,\n",
       " 'vava': 2313,\n",
       " '69911': 5280,\n",
       " 'open': 652,\n",
       " 'city': 1761,\n",
       " 'sozi': 7975,\n",
       " 'bite': 2483,\n",
       " 'uks': 2866,\n",
       " 'indicate': 4243,\n",
       " 'fml': 1912,\n",
       " '2': 4,\n",
       " 'stifled': 6065,\n",
       " 'stuffed': 5097,\n",
       " 'definitly': 7991,\n",
       " 'bits': 4979,\n",
       " 'coccooning': 6924,\n",
       " 'floppy': 7951,\n",
       " 'snatch': 5329,\n",
       " 'fooled': 5676,\n",
       " 'boyfriend': 3626,\n",
       " 'remembr': 3522,\n",
       " 'depressed': 3458,\n",
       " 'scrumptious': 4891,\n",
       " 'cutefrnd': 2382,\n",
       " 'arun': 2732,\n",
       " 'arul': 5941,\n",
       " 'attracts': 7332,\n",
       " 'illness': 4346,\n",
       " 'sao': 4449,\n",
       " 'sam': 1683,\n",
       " 'sac': 4104,\n",
       " 'turned': 4980,\n",
       " 'argument': 1684,\n",
       " 'sae': 557,\n",
       " 'sad': 563,\n",
       " 'woah': 8188,\n",
       " 'say': 109,\n",
       " 'sar': 3469,\n",
       " 'saw': 475,\n",
       " 'sat': 360,\n",
       " '1cup': 7853,\n",
       " 'zoe': 3408,\n",
       " 'babysit': 7037,\n",
       " 'aproach': 3875,\n",
       " '15pm': 7982,\n",
       " 'note': 2243,\n",
       " 'taka': 8311,\n",
       " 'algarve': 3005,\n",
       " 'take': 54,\n",
       " 'wanting': 2087,\n",
       " 'ericson': 6507,\n",
       " 'handing': 6527,\n",
       " 'printer': 6642,\n",
       " 'opposite': 8219,\n",
       " 'knew': 905,\n",
       " 'buffet': 2935,\n",
       " 'printed': 3047,\n",
       " 'pages': 2218,\n",
       " 'countinlots': 6893,\n",
       " '02085076972': 7266,\n",
       " 'phil': 6856,\n",
       " 'infections': 4316,\n",
       " 'drive': 585,\n",
       " 'werethe': 4652,\n",
       " 'salt': 8552,\n",
       " 'annoncement': 4471,\n",
       " 'walking': 1418,\n",
       " '5wq': 6494,\n",
       " 'inclu': 8787,\n",
       " 'bright': 2148,\n",
       " \"joke's\": 7724,\n",
       " '5wb': 1417,\n",
       " '5we': 1165,\n",
       " 'applyed': 8093,\n",
       " 'slow': 953,\n",
       " 'farting': 8360,\n",
       " 'robs': 6622,\n",
       " 'coaxing': 5173,\n",
       " 'foward': 8595,\n",
       " 'jaykwon': 4680,\n",
       " 'going': 30,\n",
       " 'actin': 4380,\n",
       " 'hockey': 2967,\n",
       " 'slob': 6794,\n",
       " 'caroline': 3095,\n",
       " 'carolina': 8267,\n",
       " 'b4u': 6059,\n",
       " 'psychiatrist': 5623,\n",
       " '4882': 3229,\n",
       " 'freezing': 2703,\n",
       " 'murali': 5836,\n",
       " 'compliments': 8778,\n",
       " 'awaiting': 1260,\n",
       " 'settings': 2186,\n",
       " 'getstop': 3300,\n",
       " 'borrow': 3306,\n",
       " 'tenerife': 1349,\n",
       " 'worried': 983,\n",
       " 'racal': 5057,\n",
       " 'priest': 6847,\n",
       " 'roger': 2229,\n",
       " 'worries': 1095,\n",
       " 'tortilla': 3001,\n",
       " 'where': 203,\n",
       " 'xmas': 435,\n",
       " 'busetop': 4636,\n",
       " 'persian': 8254,\n",
       " 'anyways': 1939,\n",
       " 'pisces': 8616,\n",
       " \"alex's\": 4864,\n",
       " 'cttargg': 5040,\n",
       " '8883': 8068,\n",
       " 'dormitory': 8466,\n",
       " 'x29': 6935,\n",
       " 'refreshed': 4602,\n",
       " 'availa': 4951,\n",
       " 'jobs': 3916,\n",
       " 'screen': 2653,\n",
       " \"employer's\": 4578,\n",
       " 'concentrate': 2596,\n",
       " 'spare': 3285,\n",
       " 'amore': 4361,\n",
       " 'spark': 5640,\n",
       " 'listening2the': 5370,\n",
       " 'many': 181,\n",
       " 's': 207,\n",
       " 'residency': 6382,\n",
       " '7876150ppm': 4008,\n",
       " 'expression': 3135,\n",
       " \"can't\": 173,\n",
       " 'stream': 6246,\n",
       " 'conected': 5230,\n",
       " 'call2optout': 888,\n",
       " 'anti': 2628,\n",
       " '3000': 7562,\n",
       " 'mapquest': 7963,\n",
       " 'boat': 2763,\n",
       " 'cramps': 2714,\n",
       " 'swashbuckling': 8282,\n",
       " 'stretch': 3556,\n",
       " 'west': 3983,\n",
       " 'breath': 3443,\n",
       " 'reflex': 5920,\n",
       " 'wants': 561,\n",
       " 'gist': 3279,\n",
       " 'hlday': 7689,\n",
       " 'coughing': 7214,\n",
       " '09111032124': 4641,\n",
       " '820554ad0a1705572711': 8731,\n",
       " 'photos': 1782,\n",
       " '300p': 3829,\n",
       " '09058097218': 5189,\n",
       " 'naseeb': 6203,\n",
       " 'single': 1222,\n",
       " 'squeezed': 8659,\n",
       " 'situation': 1066,\n",
       " '3uz': 2387,\n",
       " 'ive': 940,\n",
       " 'wire3': 7230,\n",
       " 'purse': 3494,\n",
       " 'bros': 2858,\n",
       " 'blah': 2424,\n",
       " 'limping': 8230,\n",
       " 'verified': 4175,\n",
       " '0125698789': 4531,\n",
       " 'thinkin': 1147,\n",
       " 'cost1': 1620,\n",
       " 'cost3': 7450,\n",
       " 'thirtyeight': 4519,\n",
       " 'downs': 6691,\n",
       " 'sterling': 6046,\n",
       " 'askin': 1514,\n",
       " 'sickness': 7651,\n",
       " 'mtnl': 8439,\n",
       " 'cheers': 1159,\n",
       " 'callon': 6652,\n",
       " 'cheery': 5381,\n",
       " 'italian': 1805,\n",
       " 'defo': 5182,\n",
       " '88888': 4013,\n",
       " 'natalie2k9': 8428,\n",
       " 'costa': 1433,\n",
       " 'volcanoes': 6949,\n",
       " 'nothin': 3848,\n",
       " \"shahjahan's\": 7248,\n",
       " 'costs': 1834,\n",
       " '1winaweek': 2776,\n",
       " 'grumpy': 4435,\n",
       " 'hubby': 3588,\n",
       " 'dimension': 5698,\n",
       " 'summer': 1128,\n",
       " 'being': 8636,\n",
       " '150p16': 3433,\n",
       " 'forevr': 2917,\n",
       " 'sum1': 2306,\n",
       " '08714712412': 8409,\n",
       " '88088': 3867,\n",
       " '6089': 8658,\n",
       " 'lolnice': 4692,\n",
       " 'ghodbandar': 5724,\n",
       " 'weekly': 486,\n",
       " '81151': 2052,\n",
       " '310303': 6900,\n",
       " 'kerala': 1578,\n",
       " 'adsense': 8420,\n",
       " 'drugdealer': 6005,\n",
       " 'f4q': 4604,\n",
       " 'starving': 6970,\n",
       " 'proze': 8011,\n",
       " 'aspects': 6427,\n",
       " 'around': 167,\n",
       " 'lnly': 5681,\n",
       " 'pos': 6486,\n",
       " 'dark': 2870,\n",
       " 'traffic': 3678,\n",
       " 'pop': 2495,\n",
       " '2geva': 4030,\n",
       " 'world': 303,\n",
       " 'postal': 5241,\n",
       " 'vague': 7497,\n",
       " 'dare': 2239,\n",
       " 'stranger': 2398,\n",
       " 'poo': 7394,\n",
       " 'quizclub': 6400,\n",
       " 'alaipayuthe': 3696,\n",
       " 'gimme': 2517,\n",
       " 'clas': 8278,\n",
       " 'gimmi': 7460,\n",
       " 'slovely': 5725,\n",
       " 'masteriastering': 7149,\n",
       " 'ortxt': 8361,\n",
       " '4few': 5229,\n",
       " 'monthlysubscription': 4720,\n",
       " 'playin': 7537,\n",
       " '5wkg': 5142,\n",
       " 'thinks': 773,\n",
       " \"there'll\": 8176,\n",
       " 'strewn': 5857,\n",
       " 'memories': 8213,\n",
       " 'noon': 1121,\n",
       " \"''ok''\": 1859,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...,   20 4361   98]\n",
      " [   0    0    0 ...,  422    2 1885]\n",
      " [   0    0    0 ...,  618  343 2936]\n",
      " ..., \n",
      " [   0    0    0 ...,   33  504 8817]\n",
      " [   0    0    0 ...,  993  151   12]\n",
      " [   0    0    0 ...,   88  436  219]]\n"
     ]
    }
   ],
   "source": [
    "print(data_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Split the data into train,test and validation sets\n",
    "#First split train and test parts, then split train part to train and validation parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_sequences, labels, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define Parameters\n",
    "#Vocab size plus one for 0, the int number that added for padding\n",
    "n_input = len(word_index)+1\n",
    "# number of units\n",
    "num_hidden = 256\n",
    "lstm_layer_numbers=2\n",
    "embed_size=300\n",
    "batch_size= 250\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "('Epoch:', 1, 'cost_train=', 0.23654443770647046, 'cost_val=', 0.23248936732610065)\n",
      "('acc_train=', 0.63759224329675945, 'acc_val=', 0.78982198238372803)\n",
      "('Epoch:', 2, 'cost_train=', 0.23368214390107564, 'cost_val=', 0.22953258951505029)\n",
      "('acc_train=', 0.65787559747695923, 'acc_val=', 0.80250777800877882)\n",
      "('Epoch:', 3, 'cost_train=', 0.22993492228644236, 'cost_val=', 0.22661814590295154)\n",
      "('acc_train=', 0.68526858942849289, 'acc_val=', 0.80738693475723267)\n",
      "('Epoch:', 4, 'cost_train=', 0.2268960763301168, 'cost_val=', 0.22372841338316601)\n",
      "('acc_train=', 0.70241533858435501, 'acc_val=', 0.80933860937754298)\n",
      "('Epoch:', 5, 'cost_train=', 0.22416281593697412, 'cost_val=', 0.22087885936101276)\n",
      "('acc_train=', 0.71579817363194043, 'acc_val=', 0.81324191888173436)\n",
      "('Epoch:', 6, 'cost_train=', 0.22121161435331615, 'cost_val=', 0.21803827583789825)\n",
      "('acc_train=', 0.73649974380220695, 'acc_val=', 0.82104857762654615)\n",
      "('Epoch:', 7, 'cost_train=', 0.21850442034857614, 'cost_val=', 0.21523192028204596)\n",
      "('acc_train=', 0.7509281081812722, 'acc_val=', 0.82202440500259399)\n",
      "('Epoch:', 8, 'cost_train=', 0.21552183159760069, 'cost_val=', 0.21244945625464121)\n",
      "('acc_train=', 0.75490113241331924, 'acc_val=', 0.82397605975468946)\n",
      "('Epoch:', 9, 'cost_train=', 0.21421175343649729, 'cost_val=', 0.20967903236548108)\n",
      "('acc_train=', 0.76305629951613285, 'acc_val=', 0.825927734375)\n",
      "('Epoch:', 10, 'cost_train=', 0.21026445499488286, 'cost_val=', 0.20695790151755011)\n",
      "('acc_train=', 0.77267521194049282, 'acc_val=', 0.82787938912709547)\n",
      "('Epoch:', 11, 'cost_train=', 0.20714088210037773, 'cost_val=', 0.20426748692989349)\n",
      "('acc_train=', 0.78752179230962482, 'acc_val=', 0.82983104387919104)\n",
      "('Epoch:', 12, 'cost_train=', 0.20487729460000992, 'cost_val=', 0.20160784820715588)\n",
      "('acc_train=', 0.79086749894278396, 'acc_val=', 0.83080687125523878)\n",
      "('Epoch:', 13, 'cost_train=', 0.20227206072637013, 'cost_val=', 0.19898511469364166)\n",
      "('acc_train=', 0.79233124852180492, 'acc_val=', 0.83178271849950147)\n",
      "('Epoch:', 14, 'cost_train=', 0.19994997446026125, 'cost_val=', 0.1964009553194046)\n",
      "('acc_train=', 0.79839534844670978, 'acc_val=', 0.83178271849950147)\n",
      "('Epoch:', 15, 'cost_train=', 0.19753757438489367, 'cost_val=', 0.19385014971097309)\n",
      "('acc_train=', 0.80299569453511932, 'acc_val=', 0.83373437325159694)\n",
      "('Epoch:', 16, 'cost_train=', 0.19442050052540644, 'cost_val=', 0.19133926431337994)\n",
      "('acc_train=', 0.80780515500477379, 'acc_val=', 0.83373437325159694)\n",
      "('Epoch:', 17, 'cost_train=', 0.19210152753761836, 'cost_val=', 0.18886122604211172)\n",
      "('acc_train=', 0.81177817497934601, 'acc_val=', 0.83373437325159694)\n",
      "('Epoch:', 18, 'cost_train=', 0.18951418144362317, 'cost_val=', 0.18641660114129385)\n",
      "('acc_train=', 0.81679673705782208, 'acc_val=', 0.83763772249221802)\n",
      "('Epoch:', 19, 'cost_train=', 0.18673642831189294, 'cost_val=', 0.18402357896169028)\n",
      "('acc_train=', 0.82097886289869026, 'acc_val=', 0.83763772249221802)\n",
      "('Epoch:', 20, 'cost_train=', 0.18458035268953868, 'cost_val=', 0.18166783452033997)\n",
      "('acc_train=', 0.82306993433407383, 'acc_val=', 0.83861356973648071)\n",
      "('Epoch:', 21, 'cost_train=', 0.18268886421407973, 'cost_val=', 0.17936232189337412)\n",
      "('acc_train=', 0.82746118307113647, 'acc_val=', 0.83958939711252856)\n",
      "('Epoch:', 22, 'cost_train=', 0.18011025020054408, 'cost_val=', 0.17709792653719583)\n",
      "('acc_train=', 0.82599742923464103, 'acc_val=', 0.83958939711252856)\n",
      "('Epoch:', 23, 'cost_train=', 0.17714619530098782, 'cost_val=', 0.17487951616446176)\n",
      "('acc_train=', 0.82683386547224869, 'acc_val=', 0.84056522448857629)\n",
      "('Epoch:', 24, 'cost_train=', 0.175374156662396, 'cost_val=', 0.17268382509549457)\n",
      "('acc_train=', 0.83101599131311699, 'acc_val=', 0.84251687924067187)\n",
      "('Epoch:', 25, 'cost_train=', 0.17322369558470591, 'cost_val=', 0.17055401206016541)\n",
      "('acc_train=', 0.82620654361588619, 'acc_val=', 0.84349270661671949)\n",
      "('Epoch:', 26, 'cost_train=', 0.17131450985159191, 'cost_val=', 0.16845848659674326)\n",
      "('acc_train=', 0.83331618138722019, 'acc_val=', 0.84544436136881507)\n",
      "('Epoch:', 27, 'cost_train=', 0.16834229337317602, 'cost_val=', 0.16639579335848492)\n",
      "('acc_train=', 0.83164332594190316, 'acc_val=', 0.8464201887448628)\n",
      "('Epoch:', 28, 'cost_train=', 0.16638972503798347, 'cost_val=', 0.164379154642423)\n",
      "('acc_train=', 0.83373438034738834, 'acc_val=', 0.8473960359891255)\n",
      "('Epoch:', 29, 'cost_train=', 0.16458797880581444, 'cost_val=', 0.16240859031677246)\n",
      "('acc_train=', 0.83394349898610798, 'acc_val=', 0.8473960359891255)\n",
      "('Epoch:', 30, 'cost_train=', 0.16234255369220457, 'cost_val=', 0.16048128406206766)\n",
      "('acc_train=', 0.83289796113967896, 'acc_val=', 0.8473960359891255)\n",
      "('Epoch:', 31, 'cost_train=', 0.15995593475443978, 'cost_val=', 0.1586072345574697)\n",
      "('acc_train=', 0.83958938292094654, 'acc_val=', 0.84934769074122118)\n",
      "('Epoch:', 32, 'cost_train=', 0.15835819712706975, 'cost_val=', 0.15678417682647705)\n",
      "('acc_train=', 0.84147133997508461, 'acc_val=', 0.85129936536153161)\n",
      "('Epoch:', 33, 'cost_train=', 0.15666612450565609, 'cost_val=', 0.15499959389368692)\n",
      "('acc_train=', 0.83812563759940018, 'acc_val=', 0.85129936536153161)\n",
      "('Epoch:', 34, 'cost_train=', 0.15438338369131088, 'cost_val=', 0.15325050552686056)\n",
      "('acc_train=', 0.84126222985131405, 'acc_val=', 0.85227519273757935)\n",
      "('Epoch:', 35, 'cost_train=', 0.15253154827015739, 'cost_val=', 0.15155149002869925)\n",
      "('acc_train=', 0.84021670051983421, 'acc_val=', 0.85325102011362719)\n"
     ]
    }
   ],
   "source": [
    "inputs,targets,keep_prob=create_model_inputs()\n",
    "initial_state, outputs, final_state = build_RNN(n_input,embed_size,inputs,num_hidden,lstm_layer_numbers,keep_prob,batch_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "#second parameter: one output which indicates if the input message is spam or ham\n",
    "predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid,\n",
    "                                                weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                                biases_initializer=tf.zeros_initializer())\n",
    "\n",
    "loss_function = tf.losses.mean_squared_error(targets, predictions)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate).minimize(loss_function)\n",
    "correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))    \n",
    "\n",
    "\n",
    "#Execute the graph\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess.run(init_op)\n",
    "no_of_batches_train = int(len(X_train)/batch_size)\n",
    "no_of_batches_valid = int(len(X_val)/batch_size)\n",
    "\n",
    "epochs = 35\n",
    "for epoch in range(epochs):\n",
    "    state = sess.run(initial_state)\n",
    "    avg_cost_train = 0 \n",
    "    avg_acc_train= 0\n",
    "    for ii, (x, y) in enumerate(get_batches(X_train, y_train, batch_size), 1):\n",
    "        _, cost, acc= sess.run([optimizer, loss_function,accuracy], feed_dict={inputs: x,\n",
    "                                                        targets: y[:, None],keep_prob: 0.5,initial_state: state})\n",
    "        \n",
    "        avg_cost_train += cost / no_of_batches_train\n",
    "        avg_acc_train += acc / no_of_batches_train\n",
    "    state_val = sess.run(initial_state)\n",
    "    avg_cost_val = 0  \n",
    "    avg_acc_val = 0\n",
    "    for ii, (x, y) in enumerate(get_batches(X_val, y_val, batch_size), 1):\n",
    "        _, cost, acc= sess.run([optimizer, loss_function, accuracy], feed_dict={inputs: x,\n",
    "                                                        targets: y[:, None],keep_prob: 1,initial_state: state_val})\n",
    "        \n",
    "        avg_cost_val += cost / no_of_batches_valid\n",
    "        avg_acc_val += acc / no_of_batches_valid\n",
    "    print(\"Epoch:\", epoch+1, \"cost_train=\", avg_cost_train, \"cost_val=\", avg_cost_val)\n",
    "    print(\"acc_train=\", avg_acc_train, \"acc_val=\", avg_acc_val) \n",
    "#Save the model into a file \n",
    "checkpoint=\"./model/savedmodel.ckpt\"\n",
    "save_path = saver.save(sess, checkpoint)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/savedmodel.ckpt\n",
      "('Test loss', 0.14462399482727051)\n",
      "('Test Accuracy', 0.85788622498512268)\n"
     ]
    }
   ],
   "source": [
    "#Test the saved model\n",
    "no_of_batches_test = int(len(X_test)/batch_size)\n",
    "sess = tf.Session()\n",
    "# Load the model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, checkpoint)\n",
    "state_test = sess.run(initial_state)\n",
    "avg_cost_test = 0  \n",
    "avg_acc_test = 0  \n",
    "for ii, (x, y) in enumerate(get_batches(X_test, y_test, batch_size), 1):\n",
    "    _, cost, acc = sess.run([optimizer, loss_function, accuracy], feed_dict={inputs: x,\n",
    "                                                    targets: y[:, None],keep_prob: 1,initial_state: state_test})\n",
    "    avg_cost_test += cost / no_of_batches_test\n",
    "    avg_acc_test += acc / no_of_batches_test\n",
    "print(\"Test loss\",avg_cost_test) \n",
    "print(\"Test Accuracy\",avg_acc_test)\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
